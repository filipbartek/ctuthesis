%\newcommand*{\IncludePaper}[2][height=\paperheight-1.5in]{\includepdf[pages=-, pagecommand={}, #1]{#2}}
\newcommand*{\IncludePaper}[2][height=\paperheight-1.5in]{\includepdf[pages=1, pagecommand={}, #1]{#2}}
%\newcommand*{\IncludePaper}[2][]{}

\newcommand{\ResultSection}{\chapter}

\todo[inline]{Consider categorizing the papers into chapters by topic:
Symbol Precedences,
Clause Selection,
Strategy Schedules
}
\todo[inline]{Emphasize that all of the solutions use ML for preprocessing.}
\todo[inline]{Mention that the NNs can be swapped -- these results show an example of a NN.}

\ResultSection{Learning Precedences from Simple Symbol Features}
\label{sec:results:simple}

State-of-the-art \glspl{atper}, including \gls{vampire}, use the \gls{SuperpositionCalculus} as the core of the reasoning procedure.
The inferences of the \gls{SuperpositionCalculus} are restricted by a \gls{sot}.
Various schemes have been used to instantiate the ordering,
for example,
\gls{kbo} and \gls{lpo}.
Both of these \gls{to} schemes are parameterized by a \gls{sp} -- a permutation of the symbols in the signature.

The standard heuristic methods implemented in \gls{vampire} construct the \gls{precedence} by sorting the symbols by their arity or number of occurrences in the input problem.
In the work presented below \cite{DBLP:conf/cade/Bartek020},
a \gls{precedence} is constructed using a combination of six simple symbol features,
including the arity and the occurrence count.
Once the system has been trained,
a precedence is constructed in two steps:
\begin{enumerate}
\item A pairwise preference regressor (Elastic-Net or Gradient Boosting) predicts a preference value for each pair of symbols.
\item A precedence is constructed using the predicted symbol pair preference values.
\end{enumerate}
The preference regressor is trained on runs of Vampire with \gls{kbo} instantiated by random precedences.
The training aims to minimize the time it takes Vampire to solve an input problem.

The main contribution of this work is the establishment of a method of using pairwise ranking as a proxy task in \gls{ml} for \gls{atping} (in this case, for training a \gls{sp} recommender).
This proved especially useful in my subsequent research,
as presented in \cref{sec:results:npr,sec:results:selection}.

\IncludePaper{publications/simple.pdf}

\ResultSection{Neural Precedence Recommender}
\label{sec:results:npr}

A \gls{gnn} can be used to extract task-specific features of various syntactic elements of an input problem,
including the predicate and function symbols.
In the work presented below \cite{DBLP:conf/cade/Bartek021},
I trained a \gls{gnn} to predict a score for each symbol in the signature such that ordering the symbols by their scores yields a good \gls{sp} for \gls{kbo} in Vampire.

%This work capitalizes on casting the task of training a \gls{sp} recommender as a pairwise ranking task.

A straightforward way to determine the best precedence for a given problem involves evaluating all possible precedences (permutations of the signature of the problem).
This is prohibitively expensive on all but the smallest problems.
On the other hand, we can easily compare an arbitrary pair of precedences.
Following from this observation, we train the symbol score predictor on the proxy task of (pairwise) ranking of precedences.

In summary, our \gls{sp} recommender is trained on three nested proxy tasks:
\begin{enumerate}
\item Predicting a score of a symbol
\item Predicting a score of a precedence
\item Pairwise ranking of precedences
\end{enumerate}

Experiments presented in the paper demonstrate that a trained precedence recommender outperforms the baseline by more than \SI{4}{\percent} in the number of solved problems.
This confirms that the proxy tasks are aligned with the main task of solving more problems and demonstrates the potential of customizing symbol precedence automatically.

% R1:
%The paper is impressive: performing machine learning for
%automated theorem proving has so far proved to be notoriously hard
%and new well-explained results in this direction are very welcome. Also, the
%level of detail is sufficient for getting a good insight, which
%is not too common for really complex methods.

% R2:
%  This paper does a good job at presenting both superposition theorem proving and GCN learning at an abstract enough
%  level that researchers in both domains can get an idea of what is going on in the other domain. 
%  The process of training the GCN is also clearly described.

This paper was published at \gls{cade} 2021.
Besides the improvement in performance,
the reviewers praised the clear and detailed presentation of the \gls{gnn} that serves as the backend of the recommender.

\IncludePaper{publications/Neural Precedence Recommender.pdf}

\ResultSection{A GNN-Advised Clause Selection}
\label{sec:results:selection}

In the work presented below \cite{DBLP:conf/lpar/Bartek023},
we turned our attention to clause selection,
arguably the most important heuristic choice point in a saturation-based prover.
We used the \gls{gnn} architecture
that proved useful in precedence recommendation (see \cref{sec:results:npr})
and trained a \gls{nn} that proposes symbol weights to configure the symbol-counting clause selection heuristic \cite{DBLP:conf/cade/SchulzM16,E-manual}.

For each problem, the \gls{nn} is only evaluated once as a preprocessing step to determine the symbol weights.
This approach allows using the optimized clause selection procedure implemented in Vampire
with very little modification and negligible computational cost during runtime.

The trained system increased the performance of a baseline Vampire by \SI{6.6}{\percent},
which is more than the increase introduced by AVATAR,
a powerful technique that delegates some propositional sub-tasks of the \gls{fol} proof search to a highly optimized \gls{sat} solver.
%integrates a \gls{sat} solver into the saturation-based proof search.
Manual inspection revealed that
the system learned to
prioritize clauses with occurrences of symbols that appear in the conjecture (goal-directed guidance),
deprioritize clauses with subformula names,
and prioritize general clauses -- clauses with variable occurrences.

\IncludePaper{publications/weights.pdf}

\ResultSection{Regularization in Spider-Style Strategy Discovery and Schedule Construction}
\label{sec:results:regularization}

In the research presented below \cite{DBLP:conf/ijcar/BartekCS24},
my co-authors and I created a system that automatically generates strong and mutually complementary strategies (configurations) for the \gls{atper} Vampire.
Using approximately 1000 strategies generated by this system,
we constructed strong strategy schedules that generalize well to unseen problems.

A greedy algorithm is at the core of the strategy construction process.
The algorithm is parameterized with several regularizing options.
These new variants of the algorithm along with an analysis of their regularizing strength
constitute the main contributions presented in the paper.

A manuscript with additional appendices is available online \cite{DBLP:journals/corr/abs-2403-12869}.

\IncludePaper{publications/regularization.pdf}

\ResultSection{Cautious Specialization of Strategy Schedules}
\label{sec:results:cautious}

In \cref{sec:results:regularization},
my co-authors and I focused on constructing a monolithic strategy schedule that performs well on the whole target set of problems.
The performance of the prover can be further increased by dividing the target set of problems into classes
and constructing a specialized schedule for each of the classes.
Each of such classes should be identified by problem features that are easy to compute
so that the branching system of schedules can be used on an unseen problem efficiently.

As long as the classes are relatively homogeneous with respect to the performance of the strategies,
this approach is expected to yield an improvement of performance on the training problems.
However, aggressive specialization may lead to a decreased performance on unseen problems.

In the extended abstract presented below \cite{DBLP:conf/paar/BartekC024},
we expanded on the work introduced in \cref{sec:results:regularization}
by investigating the problem of specialization of strategy schedules.
We performed two initial experiments:
\begin{enumerate}
\item First, we compared a hand-tweaked split of the problem space into three classes by the number of atoms to a random split.
\item Second, we experimented with training a collection of boosting trees to effectively tailor a schedule for an arbitrary input problem.
\end{enumerate}

While the first experiment showed that the choice of problem features to split on may have a large impact on generalization,
the second experiment represents a viable solution to the schedule specialization task as a whole.\todo{Consider rewording.}\todo{Consider discussing possible future work.}

\IncludePaper{publications/cautious.pdf}
